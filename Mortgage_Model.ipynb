{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXT7NcU2Nzt3HNjEdzKW9N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taha-Fintech/psx-data-reader/blob/master/Mortgage_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZMHKP6SDpP-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def generate_sample_data(num_records):\n",
        "    data = {\n",
        "        'Account_Id': [],\n",
        "        'Installment_Amount': [],\n",
        "        'Expat_Flag': [],\n",
        "        'LTV_Ratio': [],\n",
        "        'Current_LTV': [],\n",
        "        'Preferred_Flag': [],\n",
        "        'BankingWith_Us': [],\n",
        "        'Customer_Bscore': [],\n",
        "        'Score_Type': []  # New column for Score_Type\n",
        "    }\n",
        "\n",
        "    for _ in range(num_records):\n",
        "        account_id = f\"MG{random.randint(100000000, 999999999)}\"\n",
        "        installment_amount = random.randint(1000, 20000)\n",
        "        expat_flag = random.choice([0, 1])\n",
        "        ltv_ratio = round(random.uniform(0.001, 1000), 3)\n",
        "        current_ltv = round(random.uniform(0.001, 1000), 3)\n",
        "        preferred_flag = random.choice([0, 1])\n",
        "        banking_with_us = random.choice([0, 1])\n",
        "        customer_bscore = random.randint(400, 1000)\n",
        "        score_type = random.choice(['A-Score', 'B-Score'])\n",
        "\n",
        "        data['Account_Id'].append(account_id)\n",
        "        data['Installment_Amount'].append(installment_amount)\n",
        "        data['Expat_Flag'].append(expat_flag)\n",
        "        data['LTV_Ratio'].append(ltv_ratio)\n",
        "        data['Current_LTV'].append(current_ltv)\n",
        "        data['Preferred_Flag'].append(preferred_flag)\n",
        "        data['BankingWith_Us'].append(banking_with_us)\n",
        "        data['Customer_Bscore'].append(customer_bscore)\n",
        "        data['Score_Type'].append(score_type)\n",
        "\n",
        "    data = pd.DataFrame(data)\n",
        "\n",
        "    # Define binning details for each variable\n",
        "    bins_and_labels = {\n",
        "        'Installment_Amount': ([0, 2000, 4000, 6000, 1000000], [0.907957531, 0.5539907, -0.000453425, -0.294633949]),\n",
        "        'Expat_Flag': ([0, 1, 2], [0.50465208, -0.129312869]),\n",
        "        'LTV_Ratio': ([-1000000, 0.99, 1.2, 1000000000000], [-0.461206544, 0.242451227, 0.658470652]),\n",
        "        'Current_LTV': ([-1000000, 0.65, 1.1, 1.7, 10000000000], [-0.380283095, -0.02436255, 0.875635759, 1.62191051]),\n",
        "        'Preferred_Flag': ([0, 1, 2], [-0.601576706, 0.428369848]),\n",
        "        'BankingWith_Us': ([0, 1, 2], [-0.253502997, 0.278764902]),\n",
        "        'Customer_Bscore': ([-1000000, 10, 400, 580, 680, 755, 810, 1000000000000], [0.00637587, 3.158442362, 2.167616612, 0.907456144, -1.010247178, -2.297054681, -3.960001818])\n",
        "    }\n",
        "    # Perform binning for each variable\n",
        "    for col, (bins, labels) in bins_and_labels.items():\n",
        "        data[f'{col}_Bin'] = pd.cut(data[col], bins=bins, labels=labels, right=False)\n",
        "\n",
        "    return data\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    num_records = 50\n",
        "    sample_data = generate_sample_data(num_records)\n",
        "    print(sample_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_score(installment_amount, expat_flag, ratio_of_ltv, ltv, preferred_list, BankingWith_Us, bscore):\n",
        "    # Coefficients from the logistic regression equation\n",
        "    coefficients = {\n",
        "        'Intercept': -4.063439,\n",
        "        'InstallmentAmount': 0.4444435,\n",
        "        'ExpatFlag': 1.0808872,\n",
        "        'RatioOfLTV': 0.3500753,\n",
        "        'LTV': 0.5838034,\n",
        "        'PreferredList': 0.3105226,\n",
        "        'BankingWith_Us': 0.53339257,\n",
        "        'Bscore': 0.9546275\n",
        "    }\n",
        "\n",
        "    # Calculate the score using the logistic regression equation\n",
        "    score = coefficients['Intercept'] + \\\n",
        "            coefficients['InstallmentAmount'] * installment_amount + \\\n",
        "            coefficients['ExpatFlag'] * expat_flag + \\\n",
        "            coefficients['RatioOfLTV'] * ratio_of_ltv + \\\n",
        "            coefficients['LTV'] * ltv + \\\n",
        "            coefficients['PreferredList'] * preferred_list + \\\n",
        "            coefficients['BankingWith_Us'] * BankingWith_Us + \\\n",
        "            coefficients['Bscore'] * bscore\n",
        "\n",
        "    # Calculate EstimatedPD using the logistic function\n",
        "    estimated_pd = np.exp(score) / (1 + np.exp(score))\n",
        "\n",
        "    # Calculate PredictedOdds\n",
        "    predicted_odds = (1 - estimated_pd) / estimated_pd\n",
        "\n",
        "    # Offset and Factor for Scaled Score transformation\n",
        "    offset = 554\n",
        "    factor = 43\n",
        "\n",
        "    # Calculate Scaled Score using the transformation formula\n",
        "    scaled_score = offset + factor * np.log(predicted_odds)\n",
        "\n",
        "    # Add a lookup table for scaled_score to PD_TTC mapping\n",
        "    scaled_score_to_pd_ttc = {\n",
        "    -1000: 0.3354,\n",
        "    610: 0.1677,\n",
        "    640: 0.0612,\n",
        "    690: 0.0306,\n",
        "    720: 0.0138,\n",
        "    760: 0.0054,\n",
        "    800: 0.0031,\n",
        "    810: 0.0019,\n",
        "    840: 0.0012,\n",
        "    850: 0.001,\n",
        "    860: 0.0005,\n",
        "    910: 0.0002,\n",
        "    100000: 0.0051\n",
        "}\n",
        "    # Map scaled_score to PD_TTC using the lookup table\n",
        "    pd_ttc = scaled_score.map(scaled_score_to_pd_ttc)\n",
        "\n",
        "    return score, estimated_pd, predicted_odds, scaled_score, pd_ttc\n",
        "\n",
        "    # Calculate scaled_score and PD_TTC for each row in the DataFrame\n",
        "    (\n",
        "        sample_data['Score'],\n",
        "        sample_data['Estimated_PD'],\n",
        "        sample_data['Predicted_Odds'],\n",
        "        sample_data['Scaled_Score'],\n",
        "        sample_data['PD_TTC']\n",
        "    ) = zip(*sample_data.apply(lambda row: calculate_score(\n",
        "        row['Installment_Amount_Bin'],\n",
        "        row['Expat_Flag_Bin'],\n",
        "        row['LTV_Ratio_Bin'],\n",
        "        row['LTV_Bin'],\n",
        "        row['Preferred_Flag_Bin'],\n",
        "        row['BankingWith_Us_Bin'],\n",
        "        row['Bscore_Bin']\n",
        "    ), axis=1))\n",
        "\n",
        "    # Calculate distribution of records based on PD_TTC\n",
        "    pd_ttc_distribution = sample_data['PD_TTC'].value_counts()\n",
        "\n",
        "    print(\"Sample Data:\")\n",
        "    print(sample_data)\n",
        "    print(\"\\nDistribution of records based on PD_TTC:\")\n",
        "    print(pd_ttc_distribution)\n"
      ],
      "metadata": {
        "id": "M1Q0eEcbE03R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tazeM9NsE-Wu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}